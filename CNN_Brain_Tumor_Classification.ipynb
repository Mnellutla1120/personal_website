{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2645886,
          "sourceType": "datasetVersion",
          "datasetId": 1608934
        }
      ],
      "dockerImageVersionId": 30527,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mnellutla1120/personal_website/blob/main/CNN_Brain_Tumor_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow tensorflow-io"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:29:32.136351Z",
          "iopub.execute_input": "2023-12-06T22:29:32.136774Z",
          "iopub.status.idle": "2023-12-06T22:30:47.677532Z",
          "shell.execute_reply.started": "2023-12-06T22:29:32.136742Z",
          "shell.execute_reply": "2023-12-06T22:30:47.673906Z"
        },
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "pIMJAy6p4lJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f2caf03-f668-4bb7-a8b8-b57c045f40b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-io, ml-dtypes, tensorboard, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0 tensorflow-io-0.37.1\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# General Imports\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Building Model\n",
        "from keras.utils import plot_model\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import legacy\n",
        "\n",
        "# Training Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Data Processing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import load_img"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-12-06T22:30:59.567577Z",
          "iopub.execute_input": "2023-12-06T22:30:59.569458Z",
          "iopub.status.idle": "2023-12-06T22:30:59.598208Z",
          "shell.execute_reply.started": "2023-12-06T22:30:59.569338Z",
          "shell.execute_reply": "2023-12-06T22:30:59.594083Z"
        },
        "trusted": true,
        "id": "Qz-xaSea4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "SAVE = False\n",
        "SEED = 111\n",
        "\n",
        "# Setting seed for consistent results\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Data Visualization updates\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.rcParams[\"figure.figsize\"] = (16, 10)\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "# Data Classifications\n",
        "CLASS_TYPES = ['pituitary', 'notumor', 'meningioma', 'glioma']\n",
        "N_TYPES = len(CLASS_TYPES)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:31:10.282713Z",
          "iopub.execute_input": "2023-12-06T22:31:10.284337Z",
          "iopub.status.idle": "2023-12-06T22:31:10.298624Z",
          "shell.execute_reply.started": "2023-12-06T22:31:10.284288Z",
          "shell.execute_reply": "2023-12-06T22:31:10.296996Z"
        },
        "trusted": true,
        "id": "Q8oasagN4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***\n",
        "<a name='import_data'>\n",
        "    \n",
        "# 3 <span style='color:blue'>|</span> Importing Data"
      ],
      "metadata": {
        "id": "SAPyLPul4lJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for inporting data\n",
        "def get_data_labels(directory, shuffle=True, random_state=0):\n",
        "    \"\"\"\n",
        "    Function used for going into the main training directory\n",
        "    whose directory has sub-class-types.\n",
        "    \"\"\"\n",
        "    from sklearn.utils import shuffle\n",
        "    import os\n",
        "\n",
        "    # Lists to store data and labels\n",
        "    data_path = []\n",
        "    data_labels = []\n",
        "\n",
        "    for label in os.listdir(directory):\n",
        "        label_dir = os.path.join(directory, label)\n",
        "\n",
        "        # Avoid MacOS storing path\n",
        "        if not os.path.isdir(label_dir):\n",
        "            continue\n",
        "\n",
        "        # Going into each folder and getting image path\n",
        "        for image in os.listdir(label_dir):\n",
        "            image_path = os.path.join(label_dir, image)\n",
        "            data_path.append(image_path)\n",
        "            data_labels.append(label)\n",
        "\n",
        "    if shuffle:\n",
        "        data_path, data_labels = shuffle(data_path, data_labels, random_state=random_state)\n",
        "\n",
        "    return data_path, data_labels\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:31:11.484679Z",
          "iopub.execute_input": "2023-12-06T22:31:11.485113Z",
          "iopub.status.idle": "2023-12-06T22:31:11.497358Z",
          "shell.execute_reply.started": "2023-12-06T22:31:11.485082Z",
          "shell.execute_reply": "2023-12-06T22:31:11.495748Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "D-yVyBhh4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up file paths for training and testing\n",
        "USER_PATH = r\"/kaggle/input/brain-tumor-mri-dataset\"\n",
        "train_dir = USER_PATH + r'/Training/'\n",
        "test_dir = USER_PATH + r'/Testing/'\n",
        "\n",
        "# Getting data using above function\n",
        "train_paths, train_labels = get_data_labels(train_dir)\n",
        "test_paths, test_labels = get_data_labels(test_dir)\n",
        "\n",
        "# Printing traing and testing sample sizes\n",
        "print('Training')\n",
        "print(f'Number of Paths: {len(train_paths)}')\n",
        "print(f'Number of Labels: {len(train_labels)}')\n",
        "print('\\nTesting')\n",
        "print(f'Number of Paths: {len(test_paths)}')\n",
        "print(f'Number of Labels: {len(test_labels)}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:31:12.057178Z",
          "iopub.execute_input": "2023-12-06T22:31:12.058201Z",
          "iopub.status.idle": "2023-12-06T22:31:13.7854Z",
          "shell.execute_reply.started": "2023-12-06T22:31:12.058155Z",
          "shell.execute_reply": "2023-12-06T22:31:13.784085Z"
        },
        "trusted": true,
        "id": "hCLz2LIf4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "<a name='vis'>\n",
        "    \n",
        "# 4 <span style='color:blue'>|</span> Data Visualization\n",
        "    \n",
        "## <b> 4.2 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'>  Data Distributions <b>"
      ],
      "metadata": {
        "id": "AMV6lZsd4lJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, ax = plt.subplots(ncols=3, figsize=(20, 14))\n",
        "\n",
        "# Plotting training data types\n",
        "class_counts = [len([x for x in train_labels if x == label]) for label in CLASS_TYPES]\n",
        "print('Training Counts')\n",
        "print(dict(zip(CLASS_TYPES, class_counts)))\n",
        "\n",
        "ax[0].set_title('Training Data')\n",
        "ax[0].pie(\n",
        "    class_counts,\n",
        "    labels=[label.title() for label in CLASS_TYPES],\n",
        "    colors=['#FAC500','#0BFA00', '#0066FA','#FA0000'],\n",
        "    autopct=lambda p: '{:.2f}%\\n{:,.0f}'.format(p, p * sum(class_counts) / 100),\n",
        "    explode=tuple(0.01 for i in range(N_TYPES)),\n",
        "    textprops={'fontsize': 20}\n",
        ")\n",
        "\n",
        "# Plotting distribution of train test split\n",
        "ax[1].set_title('Train Test Split')\n",
        "ax[1].pie(\n",
        "    [len(train_labels), len(test_labels)],\n",
        "    labels=['Train','Test'],\n",
        "    colors=['darkcyan', 'orange'],\n",
        "    autopct=lambda p: '{:.2f}%\\n{:,.0f}'.format(p, p * sum([len(train_labels), len(test_labels)]) / 100),\n",
        "    explode=(0.1, 0),\n",
        "    startangle=85,\n",
        "    textprops={'fontsize': 20}\n",
        ")\n",
        "\n",
        "# Plotting testing data types\n",
        "class_counts = [len([x for x in test_labels if x == label]) for label in CLASS_TYPES]\n",
        "print('\\nTesting Counts')\n",
        "print(dict(zip(CLASS_TYPES, class_counts)))\n",
        "\n",
        "ax[2].set_title('Testing Data')\n",
        "ax[2].pie(\n",
        "    class_counts,\n",
        "    labels=[label.title() for label in CLASS_TYPES],\n",
        "    colors=['#FAC500', '#0BFA00', '#0066FA', '#FA0000'],\n",
        "    autopct=lambda p: '{:.2f}%\\n{:,.0f}'.format(p, p * sum(class_counts) / 100),\n",
        "    explode=tuple(0.01 for i in range(N_TYPES)),  # Explode the slices slightly for better visualization\n",
        "    textprops={'fontsize': 20}  # Set the font size for the text on the pie chart\n",
        ")\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-12-06T22:31:14.878118Z",
          "iopub.execute_input": "2023-12-06T22:31:14.878505Z",
          "iopub.status.idle": "2023-12-06T22:31:15.829337Z",
          "shell.execute_reply.started": "2023-12-06T22:31:14.878474Z",
          "shell.execute_reply": "2023-12-06T22:31:15.828537Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "8qhev5LR4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "A balanced distribution of categories in our training data is crucial for optimal model learning. It allows for comprehensive understanding of each category's characteristics, prevents biases, enhances generalization, and enables iterative refinement, leading to improved performance in accurately categorizing new data.\n",
        "\n",
        "We also have a nice split percentage in our training and testing set."
      ],
      "metadata": {
        "id": "Wm6mqKSB4lJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting image to test output\n",
        "im = load_img(train_paths[3], target_size=(150, 150))\n",
        "im = img_to_array(im)\n",
        "\n",
        "# Reshape it to (1, 150, 150, 3)\n",
        "im = np.expand_dims(im, axis=0)\n",
        "print(f'x reshaped: {im.shape}')\n",
        "\n",
        "# normilzation tensor\n",
        "im /= np.max(im) # ~ np.max(img_tensor)\n",
        "\n",
        "# Convert the array back to the image format\n",
        "im = array_to_img(im[0])\n",
        "display(im)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:31:27.662083Z",
          "iopub.execute_input": "2023-12-06T22:31:27.662511Z",
          "iopub.status.idle": "2023-12-06T22:31:27.704244Z",
          "shell.execute_reply.started": "2023-12-06T22:31:27.662465Z",
          "shell.execute_reply": "2023-12-06T22:31:27.702811Z"
        },
        "trusted": true,
        "id": "MrKx4wpj4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display a list of images based on the given index\n",
        "def show_images(paths, label_paths, index_list=range(10), im_size=250, figsize=(12, 8), save=False):\n",
        "    \"\"\"\n",
        "    Show images from a given path based on the inputted\n",
        "    list indices related to the desired images one wishes\n",
        "    to see.\n",
        "    \"\"\"\n",
        "\n",
        "    num_images = len(index_list)\n",
        "    num_rows = (num_images + 3) // 4\n",
        "\n",
        "    _, ax = plt.subplots(nrows=num_rows, ncols=4, figsize=figsize)\n",
        "    ax = ax.flatten()\n",
        "\n",
        "    for i, index in enumerate(index_list):\n",
        "        if i >= num_images:\n",
        "            break\n",
        "\n",
        "        image = load_img(paths[index], target_size=(im_size, im_size))\n",
        "        ax[i].imshow(image)\n",
        "        ax[i].set_title(f'{index}: {label_paths[index]}')\n",
        "        ax[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save:\n",
        "        plt.savefig('show_image.pdf')\n",
        "    else:\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:31:29.103393Z",
          "iopub.execute_input": "2023-12-06T22:31:29.103797Z",
          "iopub.status.idle": "2023-12-06T22:31:29.114178Z",
          "shell.execute_reply.started": "2023-12-06T22:31:29.103765Z",
          "shell.execute_reply": "2023-12-06T22:31:29.112579Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "RSsA5oyJ4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Four different data classification images, from three different angles (images are independent)\n",
        "show_images(train_paths, train_labels, im_size=350, figsize=(13,10),\n",
        "            index_list=[0, 94, 235, 17,\n",
        "                        61, 324, 55, 45,\n",
        "                        374, 65, 391, 488])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:51:39.389438Z",
          "iopub.execute_input": "2023-12-06T22:51:39.389883Z",
          "iopub.status.idle": "2023-12-06T22:51:42.515646Z",
          "shell.execute_reply.started": "2023-12-06T22:51:39.389849Z",
          "shell.execute_reply": "2023-12-06T22:51:42.514671Z"
        },
        "trusted": true,
        "id": "Mq75fM5Q4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "<a name='DP'>\n",
        "    \n",
        "# 5 <span style='color:blue'>|</span> Data Processing & Training Setup Values"
      ],
      "metadata": {
        "id": "5D3NunA44lJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image size\n",
        "image_size = (150, 150)\n",
        "\n",
        "# Training batch size\n",
        "batch_size = 32"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:51:51.527934Z",
          "iopub.execute_input": "2023-12-06T22:51:51.528397Z",
          "iopub.status.idle": "2023-12-06T22:51:51.534216Z",
          "shell.execute_reply.started": "2023-12-06T22:51:51.528362Z",
          "shell.execute_reply": "2023-12-06T22:51:51.532947Z"
        },
        "trusted": true,
        "id": "2IDvfI_b4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=10,\n",
        "                                   brightness_range=(0.85, 1.15),\n",
        "                                   width_shift_range=0.002,\n",
        "                                   height_shift_range=0.002,\n",
        "                                   shear_range=12.5,\n",
        "                                   zoom_range=0,\n",
        "                                   horizontal_flip=True,\n",
        "                                   vertical_flip=False,\n",
        "                                   fill_mode=\"nearest\")\n",
        "\n",
        "\n",
        "# applying the generator to training data with constant seed\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=image_size,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode=\"categorical\",\n",
        "                                                    seed=SEED)\n",
        "\n",
        "# No augmentation of the test data, just rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# applying the generator to testing data with constant seed\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=image_size,\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode=\"categorical\",\n",
        "                                                  shuffle=False,\n",
        "                                                  seed=SEED)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:51:51.953461Z",
          "iopub.execute_input": "2023-12-06T22:51:51.953901Z",
          "iopub.status.idle": "2023-12-06T22:51:57.99092Z",
          "shell.execute_reply.started": "2023-12-06T22:51:51.953865Z",
          "shell.execute_reply": "2023-12-06T22:51:57.989987Z"
        },
        "trusted": true,
        "id": "kWmuua8L4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b> 5.1.1 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'> Data Augmentation Class Indices <b>"
      ],
      "metadata": {
        "id": "2r0FaYUm4lJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing class indices for training data generator\n",
        "class_indices_train = train_generator.class_indices\n",
        "class_indices_train_list = list(train_generator.class_indices.keys())\n",
        "\n",
        "\n",
        "# Displaying categorical types\n",
        "print(\"Categorical types for the training data:\")\n",
        "print(class_indices_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:51:57.993169Z",
          "iopub.execute_input": "2023-12-06T22:51:57.994195Z",
          "iopub.status.idle": "2023-12-06T22:51:58.001483Z",
          "shell.execute_reply.started": "2023-12-06T22:51:57.994157Z",
          "shell.execute_reply": "2023-12-06T22:51:57.999977Z"
        },
        "trusted": true,
        "id": "b4USkW3W4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b> 5.1.2 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'>  Showing Data Augmentation <b>"
      ],
      "metadata": {
        "id": "oWlLDN_64lJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_ImageDataGenerator(ImageDataGenerator, num_samples=5, figsize=(12, 12), save=False):\n",
        "    \"\"\"\n",
        "    Function to viusalize how the ImageDataGenerator augments the data\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate augmented samples\n",
        "    augmented_samples = train_generator.next()\n",
        "\n",
        "    # Extract images from the batch\n",
        "    images = augmented_samples[0][:num_samples]\n",
        "\n",
        "    # Display the augmented images\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=figsize)\n",
        "\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(images[i])\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save:\n",
        "        plt.savefig('show_ImageDataGenerator.pdf')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:51:58.003695Z",
          "iopub.execute_input": "2023-12-06T22:51:58.004168Z",
          "iopub.status.idle": "2023-12-06T22:51:58.014686Z",
          "shell.execute_reply.started": "2023-12-06T22:51:58.004134Z",
          "shell.execute_reply": "2023-12-06T22:51:58.013599Z"
        },
        "_kg_hide-input": true,
        "_kg_hide-output": false,
        "trusted": true,
        "id": "OdsctPgP4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "show_ImageDataGenerator(train_datagen, num_samples=5, figsize=(12.5, 8), save=SAVE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:51:58.016991Z",
          "iopub.execute_input": "2023-12-06T22:51:58.017703Z",
          "iopub.status.idle": "2023-12-06T22:51:59.353835Z",
          "shell.execute_reply.started": "2023-12-06T22:51:58.017667Z",
          "shell.execute_reply": "2023-12-06T22:51:59.352432Z"
        },
        "trusted": true,
        "id": "hm8ze_eY4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b> 5.2 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'> Training Setup Values <b>"
      ],
      "metadata": {
        "id": "zSnZEKs04lJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image shape: height, width, RBG\n",
        "image_shape = (image_size[0], image_size[1], 3)\n",
        "\n",
        "# Training epochs\n",
        "epochs = 40\n",
        "\n",
        "# Steps per epoch\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "# Validation steps\n",
        "validation_steps = test_generator.samples // batch_size\n",
        "\n",
        "print(f'Image shape: {image_shape}')\n",
        "print(f'Epochs: {epochs}')\n",
        "print(f'Batch size: {batch_size}')\n",
        "print(f'Steps Per Epoch: {steps_per_epoch}')\n",
        "print(f'Validation steps: {validation_steps}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:51:59.355397Z",
          "iopub.execute_input": "2023-12-06T22:51:59.355904Z",
          "iopub.status.idle": "2023-12-06T22:51:59.366428Z",
          "shell.execute_reply.started": "2023-12-06T22:51:59.355852Z",
          "shell.execute_reply": "2023-12-06T22:51:59.364825Z"
        },
        "trusted": true,
        "id": "X1UXw-KB4lJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "<a name='a_cnn'>\n",
        "    \n",
        "# 6 <span style='color:blue'>|</span> Analysis Functions for CNN\n",
        "    \n",
        "## <b> 6.1 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'>   Evaluation Metrics for Multi-Class Classification Tasks <b>\n",
        "\n",
        "In the case of multi-class classification with four possible outputs, some of the metrics need to be adjusted. Here we explain the metrics for multi-class classification:\n",
        "\n",
        "NOTE: In a multi-class classification problem, the concept of \"True Negatives\" is not applicable. True Negatives are specific to binary classification, where you have two classes (positive and negative).\n",
        "\n",
        "\n",
        "A `confusion matrix` is a table that summarizes the performance of a classification model. Since we have multiple classes for us we will use it to provid a breakdown of predictions versus actual class labels for each class.\n",
        "\n",
        "In a multi-class system we have:\n",
        "\n",
        "- TP (True Positives): Number of instances correctly classified as a specific class.\n",
        "- FP (False Positives): Number of instances incorrectly classified as a specific class, which do not actually belong to it.\n",
        "- FN (False Negatives): Number of instances belonging to a specific class but incorrectly classified as other classes.\n",
        "\n",
        "\n",
        "|                  | Predicted Class 1 | Predicted Class 2 | ... | Predicted Class N |\n",
        "|------------------|------------------|------------------|-----|------------------|\n",
        "| Actual Class 1   | True Positive (TP)   | False Positive (FP)  | ... | False Positive (FP) |\n",
        "| Actual Class 2   | False Positive (FP)  | True Positive (TP)   | ... | False Positive (FP) |\n",
        "| ...              | ...                | ...                | ... | ...                |\n",
        "| Actual Class N   | False Positive (FP)  | False Positive (FP) | ... | True Positive (TP)  |\n",
        "\n",
        "\n",
        "### <b> 6.1.1 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'>  Precision <b>\n",
        "Precision measures the ability of the model to correctly identify positive instances for each class among all instances predicted as positive.\n",
        "\n",
        "For each class *c*: ``` Precision_c = TP_c / (TP_c + FP_c) ```\n",
        "$$\n",
        "\\text{Precision}_c = \\frac{{\\text{TP}_c}}{{\\text{TP}_c + \\text{FP}_c}}\n",
        "$$\n",
        "\n",
        "### <b> 6.1.2 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'>  Recall (Sensitivity or True Positive Rate) <b>\n",
        "Recall calculates the ability of the model to correctly identify positive instances for each class among all actual positive instances.\n",
        "\n",
        "For each class *c*: ``` Recall_c = TP_c / (TP_c + FN_c) ```\n",
        "$$\n",
        "\\text{Recall}_c = \\frac{{\\text{TP}_c}}{{\\text{TP}_c + \\text{FN}_c}}\n",
        "$$\n",
        "\n",
        "### <b> 6.1.3 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'>  F1-Score <b>\n",
        "The F1-score is the harmonic mean of precision and recall. It provides a balanced measure that combines both metrics for each class.\n",
        "\n",
        "For each class *c*: ```F1-Score_c = 2 * (Precision_c * Recall_c) / (Precision_c + Recall_c)```\n",
        "$$\n",
        "\\text{F1-Score}_c = 2 \\times \\frac{{\\text{Precision}_c \\times \\text{Recall}_c}}{{\\text{Precision}_c + \\text{Recall}_c}}\n",
        "$$\n",
        "\n",
        "### <b> 6.1.4 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'>  Accuracy <b>\n",
        "Accuracy measures the overall correctness of the model's predictions across all classes.\n",
        "``` Accuracy = (TP_1 + TP_2 + ... + TP_N) / (TP_1 + TP_2 + ... + TP_N + FP_1 + FP_2 + ... + FP_N + FN_1 + FN_2 + ... + FN_N) ```\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{{\\text{TP}_1 + \\text{TP}_2 + ... + \\text{TP}_N}}{{\\text{TP}_1 + \\text{TP}_2 + ... + \\text{TP}_N + \\text{FP}_1 + \\text{FP}_2 + ... + \\text{FP}_N + \\text{FN}_1 + \\text{FN}_2 + ... + \\text{FN}_N}}\n",
        "$$\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "up-1x2jW4lJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –––––––––––––––––––––––––––––––––––––– #\n",
        "# Output Images and Labels Visualization #\n",
        "# –––––––––––––––––––––––––––––––––––––– #\n",
        "def plot_sample_predictions(model, test_generator, categories, test_dir, num_samples=9, figsize=(12, 8)):\n",
        "    \"\"\"\n",
        "    Nice display of prediction samples to see CNN predictions\n",
        "    for classification.\n",
        "    \"\"\"\n",
        "    # Make predictions on the test dataset\n",
        "    predictions = model.predict(test_generator)\n",
        "    predicted_categories = np.argmax(predictions, axis=1)\n",
        "    true_categories = test_generator.classes\n",
        "\n",
        "    # Randomly sample test images\n",
        "    test_images = np.array(test_generator.filepaths)\n",
        "    sample_indices = np.random.choice(len(test_images), size=num_samples, replace=False)\n",
        "    sample_images = test_images[sample_indices]\n",
        "    sample_predictions = [categories[predicted_categories[i]] for i in sample_indices]\n",
        "    sample_true_labels = [categories[true_categories[i]] for i in sample_indices]\n",
        "\n",
        "    # Plot sample images with their predicted and true labels\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # Loop over samples\n",
        "    for i, image_path in enumerate(sample_images):\n",
        "        # Form subplot and plot\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        img = plt.imread(image_path)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # Set axis label color depending on correct prediction or not\n",
        "        prediction_color = 'green' if sample_predictions[i] == sample_true_labels[i] else 'red'\n",
        "        plt.title(f\"Predicted: {sample_predictions[i]}\\nTrue: {sample_true_labels[i]}\", color=prediction_color)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# –––––––––––––––––––––––––––––––––––––– #\n",
        "#            Confusion matrix            #\n",
        "# –––––––––––––––––––––––––––––––––––––– #\n",
        "def CM(CNN_model, test_generator, categories):\n",
        "    \"\"\"\n",
        "    Function to return the confusion matrix of a given CNN model.\n",
        "    \"\"\"\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    # Predictions on test dataset\n",
        "    predictions = CNN_model.predict(test_generator)\n",
        "    predicted_categories = np.argmax(predictions, axis=1)\n",
        "    true_categories = test_generator.classes\n",
        "\n",
        "    # Create a confusion matrix\n",
        "    confusion_matrix_array = confusion_matrix(true_categories, predicted_categories)\n",
        "\n",
        "    return confusion_matrix_array\n",
        "\n",
        "\n",
        "# –––––––––––––––––––––––––––––––––––––– #\n",
        "#             Metric Analysis            #\n",
        "# –––––––––––––––––––––––––––––––––––––– #\n",
        "def calculate_metrics(confusion_matrix, categories):\n",
        "    \"\"\"\n",
        "    Function to calculate important metrics for multi-classification problems.\n",
        "    \"\"\"\n",
        "    # Calculating 4 different metrics\n",
        "    precision = np.diag(confusion_matrix) / np.sum(confusion_matrix, axis=0)\n",
        "    recall = np.diag(confusion_matrix) / np.sum(confusion_matrix, axis=1)\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    accuracy = np.sum(np.diag(confusion_matrix)) / np.sum(confusion_matrix)\n",
        "\n",
        "    # Printing the results based on each category\n",
        "    for i, category in enumerate(categories):\n",
        "        print(f\"Class: {category.title()}\")\n",
        "        print(f\"Precision: {precision[i]:.3f}\")\n",
        "        print(f\"Recall: {recall[i]:.3f}\")\n",
        "        print(f\"F1-Score: {f1_score[i]:.3f}\\n\")\n",
        "\n",
        "    # Showing the total accuracy of the model\n",
        "    print(f\"\\nAccuracy: {accuracy:.3f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:52:02.801166Z",
          "iopub.execute_input": "2023-12-06T22:52:02.801622Z",
          "iopub.status.idle": "2023-12-06T22:52:02.820819Z",
          "shell.execute_reply.started": "2023-12-06T22:52:02.801588Z",
          "shell.execute_reply": "2023-12-06T22:52:02.819602Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "RPMGp4h94lJ2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "<a name='CNN'>\n",
        "    \n",
        "# 7 <span style='color:blue'>|</span> Initial CNN Model Tests\n",
        "\n",
        "    From `model_1` I tested the following tuples and got the following test accuarcies. Since parameters `3.` rounded to two decimal places performed the best, or equally the best, we will use it as we improve our model.\n",
        "1. filter size of `filter_size = (4, 4)` and `pool_size = (2, 2)` the accuaracy was `Test Accuracy: 0.97`\n",
        "2. filter size of `filter_size = (3, 3)` and `pool_size = (3, 3)` the accuaracy was `Test Accuracy: 0.97`\n",
        "3. filter size of `filter_size = (4, 4)` and `pool_size = (3, 3)` the accuaracy was `Test Accuracy: 0.98`\n",
        "4. filter size of `filter_size = (3, 3)` and `pool_size = (2, 2)` the accuaracy was `Test Accuracy: 0.98`\n",
        "    \n",
        "Model `3.` was the tested by switched parts, then all to `model.add(AveragePooling2D(pool_size=(3, 3)))`.\n",
        "- The results were good with a `Test Accuracy score: 0.9766`. But did not improve on upon the previous model.\n",
        "    \n",
        "Model `3.` was tested with different optimizers. The optimzer test accuracy scores were as follows.\n",
        "1. Adam: `Test Accuracy: 0.982`\n",
        "2. RMSprop: `Test Accuracy: 0.972`\n",
        "3. Nadam: `Test Accuracy: 0.964`\n",
        "\n",
        "In addition various trials were done to the parameters of `ImageDataGenerator()` to help ensure that overfitting would be minimized.\n",
        "    \n",
        "***\n",
        "\n",
        "```python\n",
        "# Define the model architecture\n",
        "model_1 = models.Sequential()\n",
        "\n",
        "# Convolutional layer 1\n",
        "model_1.add(Conv2D(32, (4, 4), activation=\"relu\", input_shape=image_shape))\n",
        "model_1.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "# Convolutional layer 2\n",
        "model_1.add(Conv2D(64, (4, 4), activation=\"relu\"))\n",
        "model_1.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "# Convolutional layer 3\n",
        "model_1.add(Conv2D(128, (4, 4), activation=\"relu\"))\n",
        "model_1.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "# Convolutional layer 4\n",
        "model_1.add(Conv2D(128, (4, 4), activation=\"relu\"))\n",
        "model_1.add(Flatten())\n",
        "\n",
        "# Full connect layers\n",
        "model_1.add(Dense(512, activation=\"relu\"))\n",
        "model_1.add(Dropout(0.5, seed=SEED))\n",
        "model_1.add(Dense(N_TYPES, activation=\"softmax\"))\n",
        "\n",
        "model_1.summary()\n",
        "\n",
        "```\n",
        "***\n",
        "\n",
        "- Convolutional layer 1:\n",
        "  - Input shape: (150, 150, 3)\n",
        "  - Number of filters: 32\n",
        "  - Filter size: (4, 4)\n",
        "  - Activation function: ReLU\n",
        "  - Output shape: (147, 147, 32) [Calculation: (150 - 4) + 1 = 147]\n",
        "\n",
        "- Max Pooling layer 1:\n",
        "  - Pool size: (3, 3)\n",
        "  - Output shape: (49, 49, 32) [Calculation: 147 / 3 = 49]\n",
        "\n",
        "- Convolutional layer 2:\n",
        "  - Input shape: (49, 49, 32)\n",
        "  - Number of filters: 64\n",
        "  - Filter size: (4, 4)\n",
        "  - Activation function: ReLU\n",
        "  - Output shape: (46, 46, 64) [Calculation: (49 - 4) + 1 = 46]\n",
        "\n",
        "- Max Pooling layer 2:\n",
        "  - Pool size: (3, 3)\n",
        "  - Output shape: (15, 15, 64) [Calculation: 46 / 3 = 15]\n",
        "\n",
        "- Convolutional layer 3:\n",
        "  - Input shape: (15, 15, 64)\n",
        "  - Number of filters: 128\n",
        "  - Filter size: (4, 4)\n",
        "  - Activation function: ReLU\n",
        "  - Output shape: (12, 12, 128) [Calculation: (15 - 4) + 1 = 12]\n",
        "\n",
        "- Max Pooling layer 3:\n",
        "  - Pool size: (3, 3)\n",
        "  - Output shape: (4, 4, 128) [Calculation: 12 / 3 = 4]\n",
        "\n",
        "- Convolutional layer 4:\n",
        "  - Input shape: (4, 4, 128)\n",
        "  - Number of filters: 128\n",
        "  - Filter size: (4, 4)\n",
        "  - Activation function: ReLU\n",
        "  - Output shape: (1, 1, 128) [Calculation: (4 - 4) + 1 = 1]\n",
        "\n",
        "- Flatten layer:\n",
        "  - Reshapes the output to a 1D array of size 128.\n",
        "\n",
        "- Dense layer 1:\n",
        "  - Number of neurons: 512\n",
        "  - Activation function: ReLU\n",
        "  - Output shape: 512\n",
        "\n",
        "- Dropout layer:\n",
        "  - Dropout rate: 0.5\n",
        "  - Output shape: 512\n",
        "\n",
        "- Dense layer 2:\n",
        "  - Number of neurons: N_TYPES (the number of output classes)\n",
        "  - Activation function: Softmax\n",
        "  - Output shape: N_TYPES\n",
        "\n",
        "Total trainable parameters: 495,972 (1.89 MB)"
      ],
      "metadata": {
        "id": "OMriXH3a4lJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "<a name='CNN2'>\n",
        "    \n",
        "# 8 <span style='color:blue'>|</span> Final CNN Model\n",
        "    \n",
        "Here, we present the second version of our Convolutional Neural Network (CNN) architecture, which includes some important tweaks and additional modifications for improved performance. We have tested `BatchNormalization()` layers, which proved to be not so helpful. We also tested changing certain filter sizes such as the last `filter_size = (3,3)`. This change proved to have near no affect on the model's improvment on test accuracy.\n",
        "\n",
        "Furthermore, we performed fine-tuning on certain hyperparameters, specifically $\\beta_1$ and $\\beta_2$, which are part of the Adam optimizer. By experimenting with different values, we explored a range of $\\beta_1 \\in [0.7, 0.995]$ and $\\beta_2 \\in [0.9, 0.9995]$ to optimize the training process. After conducting an exhaustive evaluation of multiple models, we achieved the highest validation accuracy with the following configuration:\n",
        "\n",
        "**Adam Parameters:**\n",
        "- `learning_rate`: The learning rate determines the step size for adjusting the model weights during training. Higher values can lead to faster convergence, but they may also risk overshooting. The default value is 0.001.\n",
        "- `beta_1`: The exponential decay rate for the first moment estimates, controlling the exponential decay of the moving average of past gradients. The default value is 0.9.\n",
        "- `beta_2`: The exponential decay rate for the second moment estimates, controlling the exponential decay of the moving average of past squared gradients. The default value is 0.999.\n",
        "- `epsilon`: A small value added to the denominator for numerical stability. The default is 1e-7.\n",
        "- `decay`: This parameter gradually decreases the learning rate over time to fine-tune the model.\n",
        "- `amsgrad`: A boolean value indicating whether to use the AMSGrad variant of the Adam optimizer. The default is False.\n",
        "- `clipnorm`: Caps the norm of the gradients to a specified maximum value. It provides an alternative to `clipvalue`.\n",
        "- `clipvalue`: Prevents gradients from becoming too large by capping them at a specified maximum value.\n",
        "\n",
        "Additionally, to enhance the training process and prevent overfitting, we implemented the following callbacks:\n",
        "\n",
        "***\n",
        "```python\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False, start_from_epoch=0)\n",
        "ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "```\n",
        "***\n",
        "    \n",
        "With these callbacks, the model's training will stop early if the loss stops decreasing (using `EarlyStopping`), and the learning rate will be reduced if the validation loss plateaus (using `ReduceLROnPlateau`).\n",
        "\n",
        "These additional tweaks have improved the performance of our CNN model. Through experimentation and fine-tuning, we have achieved better convergence and higher validation accuracy."
      ],
      "metadata": {
        "id": "nQZSAu2p4lJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = models.Sequential([\n",
        "\n",
        "    # Convolutional layer 1\n",
        "    Conv2D(32, (4, 4), activation=\"relu\", input_shape=image_shape),\n",
        "    MaxPooling2D(pool_size=(3, 3)),\n",
        "\n",
        "    # Convolutional layer 2\n",
        "    Conv2D(64, (4, 4), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(3, 3)),\n",
        "\n",
        "    # Convolutional layer 3\n",
        "    Conv2D(128, (4, 4), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(3, 3)),\n",
        "\n",
        "    # Convolutional layer 4\n",
        "    Conv2D(128, (4, 4), activation=\"relu\"),\n",
        "    Flatten(),\n",
        "\n",
        "    # Full connect layers\n",
        "    Dense(512, activation=\"relu\"),\n",
        "    Dropout(0.5, seed=SEED),\n",
        "    Dense(N_TYPES, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizer = legacy.Adam(learning_rate=0.001, beta_1=0.869, beta_2=0.995)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:54:17.710607Z",
          "iopub.execute_input": "2023-12-06T22:54:17.711085Z",
          "iopub.status.idle": "2023-12-06T22:54:17.892812Z",
          "shell.execute_reply.started": "2023-12-06T22:54:17.711048Z",
          "shell.execute_reply": "2023-12-06T22:54:17.891527Z"
        },
        "trusted": true,
        "id": "Qvc8X6EW4lJ2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visualkeras"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-06T22:54:20.638991Z",
          "iopub.execute_input": "2023-12-06T22:54:20.639446Z",
          "iopub.status.idle": "2023-12-06T22:54:35.344292Z",
          "shell.execute_reply.started": "2023-12-06T22:54:20.639412Z",
          "shell.execute_reply": "2023-12-06T22:54:35.343078Z"
        },
        "trusted": true,
        "id": "DiwjxQBV4lJ2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from visualkeras import layered_view\n",
        "\n",
        "# Visualize the model\n",
        "layered_view(model, legend=True, max_xy=300)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:54:54.479906Z",
          "iopub.execute_input": "2023-12-06T22:54:54.480375Z",
          "iopub.status.idle": "2023-12-06T22:54:54.516179Z",
          "shell.execute_reply.started": "2023-12-06T22:54:54.480337Z",
          "shell.execute_reply": "2023-12-06T22:54:54.514871Z"
        },
        "trusted": true,
        "id": "1pIzjaOM4lJ2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_visual = models.Model(inputs=model.input, outputs=model.output)\n",
        "\n",
        "# Save model architecture to a file\n",
        "plot_model(model_visual, show_dtype=True, to_file='model_architecture.png', show_shapes=True)\n",
        "\n",
        "# Display model architecture in the notebook\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(retina=True, filename='model_architecture.png')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-06T22:55:03.14036Z",
          "iopub.execute_input": "2023-12-06T22:55:03.140786Z",
          "iopub.status.idle": "2023-12-06T22:55:03.506433Z",
          "shell.execute_reply.started": "2023-12-06T22:55:03.140754Z",
          "shell.execute_reply": "2023-12-06T22:55:03.505078Z"
        },
        "trusted": true,
        "id": "qihA7AME4lJ2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b> 8.1 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'>  Training Model <b>"
      ],
      "metadata": {
        "id": "x5i2Szl_4lJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop training if loss doesn't keep decreasing.\n",
        "model_es = EarlyStopping(monitor='loss', min_delta=1e-9, patience=8, verbose=True)\n",
        "model_rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, verbose=True)\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=validation_steps,\n",
        "                    callbacks=[model_es, model_rlr])\n"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-12-06T22:55:06.495383Z",
          "iopub.execute_input": "2023-12-06T22:55:06.495803Z"
        },
        "trusted": true,
        "id": "mL-oy1mt4lJ2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b> 8.2 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'>  Model Evaluation <b>"
      ],
      "metadata": {
        "id": "j7qRFqoX4lJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(test_generator, steps=test_generator.samples//batch_size)\n",
        "print(f\"Test Loss: {loss:0.5f}\")\n",
        "print(f\"Test Accuracy: {accuracy:0.5f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T12:12:56.58001Z",
          "iopub.execute_input": "2023-07-28T12:12:56.580509Z",
          "iopub.status.idle": "2023-07-28T12:13:06.96152Z",
          "shell.execute_reply.started": "2023-07-28T12:12:56.580469Z",
          "shell.execute_reply": "2023-07-28T12:13:06.960262Z"
        },
        "trusted": true,
        "id": "YchhorSD4lJ2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "_, ax = plt.subplots(ncols=2, figsize=(15, 6))\n",
        "\n",
        "# Plot the training and validation accuracy over epochs\n",
        "ax[0].plot(history.history['accuracy'])\n",
        "ax[0].plot(history.history['val_accuracy'])\n",
        "ax[0].set_title('Model 2 Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].legend(['Train', 'Validation'])\n",
        "ax[0].grid(alpha=0.2)\n",
        "\n",
        "# Plot the training and validation loss over epochs\n",
        "ax[1].plot(history.history['loss'])\n",
        "ax[1].plot(history.history['val_loss'])\n",
        "ax[1].set_title('Model 2 Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].legend(['Train', 'Validation'])\n",
        "ax[1].grid(alpha=0.2)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T12:13:06.96304Z",
          "iopub.execute_input": "2023-07-28T12:13:06.963639Z",
          "iopub.status.idle": "2023-07-28T12:13:07.843631Z",
          "shell.execute_reply.started": "2023-07-28T12:13:06.963604Z",
          "shell.execute_reply": "2023-07-28T12:13:07.842354Z"
        },
        "trusted": true,
        "id": "pJuLvAD04lJ2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting confusion matrix\n",
        "confusion_matrix = CM(CNN_model=model, test_generator=test_generator, categories=class_indices_train_list)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.xticks(ticks=np.arange(N_TYPES) + 0.5,\n",
        "           labels=[name.title() for name in class_indices_train_list], ha='center')\n",
        "plt.yticks(ticks=np.arange(N_TYPES) + 0.5,\n",
        "           labels=[name.title() for name in class_indices_train_list], va='center')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T12:13:07.845263Z",
          "iopub.execute_input": "2023-07-28T12:13:07.845786Z",
          "iopub.status.idle": "2023-07-28T12:13:18.688229Z",
          "shell.execute_reply.started": "2023-07-28T12:13:07.845749Z",
          "shell.execute_reply": "2023-07-28T12:13:18.687013Z"
        },
        "trusted": true,
        "id": "WcvP1GkY4lJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing metrics\n",
        "calculate_metrics(confusion_matrix, categories=class_indices_train_list)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T12:12:27.200964Z",
          "iopub.execute_input": "2023-07-28T12:12:27.201464Z",
          "iopub.status.idle": "2023-07-28T12:12:27.208199Z",
          "shell.execute_reply.started": "2023-07-28T12:12:27.201429Z",
          "shell.execute_reply": "2023-07-28T12:12:27.207229Z"
        },
        "trusted": true,
        "id": "z6IePDLj4lJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Using functions in 6.1 for showing results\n",
        "plot_sample_predictions(model=model,\n",
        "                        test_generator=test_generator,\n",
        "                        categories=class_indices_train_list,\n",
        "                        test_dir=test_dir,\n",
        "                        num_samples=9,\n",
        "                        figsize=(13, 12))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T12:12:27.209653Z",
          "iopub.execute_input": "2023-07-28T12:12:27.210302Z",
          "iopub.status.idle": "2023-07-28T12:12:38.096491Z",
          "shell.execute_reply.started": "2023-07-28T12:12:27.210266Z",
          "shell.execute_reply": "2023-07-28T12:12:38.095376Z"
        },
        "trusted": true,
        "id": "jQrMI4W64lJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b> 8.4 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'>  Deeper Look Into Model 2 <b>"
      ],
      "metadata": {
        "id": "xBYy1Lrd4lJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# channnel map plot\n",
        "def plot_channel_activation_maps(model, image, images_per_row=16, N=8, save=False):\n",
        "    \"\"\"\n",
        "    Function to visualize how the first N layers of the model observe the input image.\n",
        "\n",
        "    Parameters:\n",
        "        model (tensorflow.keras.models.Model): The Keras model for which to visualize the activation maps.\n",
        "        image (numpy.ndarray): The input image for which to generate activation maps.\n",
        "        images_per_row (int): Number of activation maps to display per row in the grid.\n",
        "        N (int): Number of layers to visualize.\n",
        "        save (bool): If True, save the plots as PDF files.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    from tensorflow.keras.models import Model\n",
        "\n",
        "    # Create a sub-model that outputs activations for the first N layers\n",
        "    activation_model = Model(inputs=model.input, outputs=[layer.output for layer in model.layers[:N]])\n",
        "    activations = activation_model.predict(image)\n",
        "\n",
        "    # Get the names of the layers for labeling the plots\n",
        "    layer_names = [layer.name for layer in model.layers[:N]]\n",
        "\n",
        "    # Visualize the feature maps for each layer\n",
        "    for layer_name, layer_activation in zip(layer_names, activations):\n",
        "        # This is the number of features in the feature map\n",
        "        n_features = layer_activation.shape[-1]\n",
        "        # The feature map has shape (1, size, size, n_features)\n",
        "        size = layer_activation.shape[1]\n",
        "        # We will tile the activation channels in this matrix\n",
        "        n_cols = n_features // images_per_row\n",
        "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "        # We'll tile each filter into this big horizontal grid\n",
        "        for col in range(n_cols):\n",
        "            for row in range(images_per_row):\n",
        "                channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
        "                # Post-process the feature to make it visually palatable\n",
        "                channel_image -= channel_image.mean()\n",
        "                epsilon = 1e-8  # A small epsilon value to avoid division by zero\n",
        "                channel_std = channel_image.std() + epsilon\n",
        "                channel_image /= channel_std\n",
        "                channel_image *= 64\n",
        "                channel_image += 128\n",
        "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "                display_grid[col * size: (col + 1) * size,\n",
        "                             row * size: (row + 1) * size] = channel_image\n",
        "\n",
        "        # Display the grid\n",
        "        scale = 1. / size\n",
        "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "                            scale * display_grid.shape[0]))\n",
        "        plt.title(layer_name)\n",
        "        plt.grid(False)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "\n",
        "        if save:\n",
        "            plt.savefig(f'plot_channel_activation_maps_{layer_name}.pdf')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T12:13:23.214816Z",
          "iopub.execute_input": "2023-07-28T12:13:23.216265Z",
          "iopub.status.idle": "2023-07-28T12:13:23.233089Z",
          "shell.execute_reply.started": "2023-07-28T12:13:23.216221Z",
          "shell.execute_reply": "2023-07-28T12:13:23.231601Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "y6ZjQX0W4lJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the next batch from the test generator\n",
        "batch_images, batch_labels = next(test_generator)\n",
        "\n",
        "# Extract the first image from the batch\n",
        "image, label = batch_images[0], batch_labels[0]\n",
        "image_tensor = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Get the class indices from the test generator\n",
        "class_indices = test_generator.class_indices\n",
        "\n",
        "# Convert the one-hot encoded label to the class name\n",
        "label_name = [k for k, v in class_indices.items() if np.argmax(label) == v][0]\n",
        "\n",
        "# Display the class name\n",
        "print(f\"Class name of the first image: {label_name}\")\n",
        "print(f'Shape {image_tensor.shape}')\n",
        "array_to_img(image_tensor[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T12:13:23.489113Z",
          "iopub.execute_input": "2023-07-28T12:13:23.489692Z",
          "iopub.status.idle": "2023-07-28T12:13:23.602698Z",
          "shell.execute_reply.started": "2023-07-28T12:13:23.489649Z",
          "shell.execute_reply": "2023-07-28T12:13:23.601478Z"
        },
        "trusted": true,
        "id": "dePt2qSb4lJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_channel_activation_maps(model=model, image=image_tensor, N=5, save=SAVE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T12:13:24.660745Z",
          "iopub.execute_input": "2023-07-28T12:13:24.661837Z",
          "iopub.status.idle": "2023-07-28T12:13:27.287978Z",
          "shell.execute_reply.started": "2023-07-28T12:13:24.661772Z",
          "shell.execute_reply": "2023-07-28T12:13:27.286748Z"
        },
        "trusted": true,
        "id": "v3a9OInU4lJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b> 8.4.2 <span style='border-left: 4px solid #0000FF; padding-left: 10px;'> Misclassified Tumors <b>"
      ],
      "metadata": {
        "id": "VJP0gvhY4lJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of mis-classsified images\n",
        "def visualize_misclassified_images(model, test_generator, class_indices):\n",
        "    \"\"\"\n",
        "    Visualize misclassified images from the test set alongside their predicted and true labels.\n",
        "\n",
        "    Parameters:\n",
        "        model (tensorflow.keras.models.Model): The trained Keras model.\n",
        "        test_generator (tensorflow.keras.preprocessing.image.DirectoryIterator): The test data generator.\n",
        "        class_indices (dict): Dictionary mapping class names to their corresponding integer labels.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    from tensorflow.keras.preprocessing.image import array_to_img\n",
        "\n",
        "    misclassified_images = []\n",
        "    misclassified_labels_true = []\n",
        "    misclassified_labels_pred = []\n",
        "\n",
        "    for i in range(len(test_generator)):\n",
        "        batch_images, batch_labels = next(test_generator)\n",
        "        batch_predictions = model.predict(batch_images, verbose=False)\n",
        "        predicted_labels = [list(class_indices.keys())[np.argmax(pred)] for pred in batch_predictions]\n",
        "        true_labels = [list(class_indices.keys())[np.argmax(label)] for label in batch_labels]\n",
        "\n",
        "        for j in range(len(batch_images)):\n",
        "            if predicted_labels[j] != true_labels[j]:\n",
        "                misclassified_images.append(batch_images[j])\n",
        "                misclassified_labels_true.append(true_labels[j])\n",
        "                misclassified_labels_pred.append(predicted_labels[j])\n",
        "\n",
        "    # Display misclassified images alongside their true and predicted labels\n",
        "    num_misclassified = len(misclassified_images)\n",
        "    num_rows = int(np.ceil(num_misclassified / 4))\n",
        "    plt.figure(figsize=(12, 3 * num_rows))\n",
        "\n",
        "    for i in range(num_misclassified):\n",
        "        plt.subplot(num_rows, 4, i + 1)\n",
        "        plt.title(f\"True: {misclassified_labels_true[i]}\\nPred: {misclassified_labels_pred[i]}\", color='red')\n",
        "        plt.imshow(array_to_img(misclassified_images[i]))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T12:13:29.409105Z",
          "iopub.execute_input": "2023-07-28T12:13:29.409965Z",
          "iopub.status.idle": "2023-07-28T12:13:29.422653Z",
          "shell.execute_reply.started": "2023-07-28T12:13:29.409917Z",
          "shell.execute_reply": "2023-07-28T12:13:29.421591Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "wwUQgDgj4lJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Using function above\n",
        "visualize_misclassified_images(model, test_generator, test_generator.class_indices)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-28T12:13:29.623402Z",
          "iopub.execute_input": "2023-07-28T12:13:29.626235Z",
          "iopub.status.idle": "2023-07-28T12:13:43.692466Z",
          "shell.execute_reply.started": "2023-07-28T12:13:29.626189Z",
          "shell.execute_reply": "2023-07-28T12:13:43.691097Z"
        },
        "trusted": true,
        "id": "na1PBIe-4lJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='end'>\n",
        "    \n",
        "***\n",
        "0. [`Return To Top of Notebook`](#T)\n",
        "1. [`About The Data`](#data)\n",
        "2. [`Imports & Setup`](#imports)\n",
        "3. [`Imports Data`](#import_data)\n",
        "4. [`Data Visualization`](#vis)\n",
        "5. [`Data Processing`](#DP)\n",
        "6. [`Analysis of CNN Output`](#a_cnn)\n",
        "7. [`First CNN`](#CNN)\n",
        "8. [`Second CNN`](#CNN2)\n",
        "9. [`End of Notebook`](#end)\n",
        "\n",
        "Author: [Math & Physics Fun with Gus](https://mathphysicsfunwithgus.square.site)\n",
        "\n",
        "<p style=\"padding: 10px;\n",
        "          background-color: yellow;\n",
        "          font-family: computermodern;\n",
        "          color: black;\n",
        "          font-size: 210%;\n",
        "          text-align: center;\n",
        "          border-radius:20px 20px;\n",
        "          \">Thank you and if you found this useful please like 👍🏼 </p>\n",
        "    \n",
        "# <b> END <span style='border-left: 4px solid #0000FF; padding-left: 10px;'>  Jupyter Notebook <b>\n",
        "***"
      ],
      "metadata": {
        "id": "6jv0hXDw4lJ5"
      }
    }
  ]
}